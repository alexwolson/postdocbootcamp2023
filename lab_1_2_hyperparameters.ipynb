{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMcD6m6l8Ut8vEnqam8Fx4F"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f6d84beb6f8e477a9c0d45817accc8b0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3996aef1fc0f4b7ea9a5f6dbaffd4fba","IPY_MODEL_330269805d30447895208d5c4f79e728","IPY_MODEL_adee0055ed694b0a9f643a489d3fb08a"],"layout":"IPY_MODEL_76b654fd1e0a4da8b4a3bb949c286086"}},"3996aef1fc0f4b7ea9a5f6dbaffd4fba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e05c7217178646a1b362f13e93d7fc00","placeholder":"​","style":"IPY_MODEL_6f35d1788d3b498ca7dccc8072a36daf","value":"Best trial: 95. Best value: 0.817528: 100%"}},"330269805d30447895208d5c4f79e728":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d85108019624c6bb12a020175c24afe","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0cd81b6de72048c8961aa7778b653a0b","value":100}},"adee0055ed694b0a9f643a489d3fb08a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a08383cb3b24b129429c401fa4e8df4","placeholder":"​","style":"IPY_MODEL_1b58e8e784a045e08d6605205d63150a","value":" 100/100 [02:04&lt;00:00,  1.24s/it]"}},"76b654fd1e0a4da8b4a3bb949c286086":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e05c7217178646a1b362f13e93d7fc00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f35d1788d3b498ca7dccc8072a36daf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2d85108019624c6bb12a020175c24afe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0cd81b6de72048c8961aa7778b653a0b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9a08383cb3b24b129429c401fa4e8df4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b58e8e784a045e08d6605205d63150a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e0aef6ccaf6d43e1b5c400b2307a265e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f21470133c574f5c9d0707c979038cbf","IPY_MODEL_ecf72f14216949e3b93f5f0f78f9baba","IPY_MODEL_6e6a13c6cb6640d2b874207cb29d487e"],"layout":"IPY_MODEL_7ea0dc58b97e422283f5822274fa68df"}},"f21470133c574f5c9d0707c979038cbf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_41c5428891fb4b9e8e00545c027a4794","placeholder":"​","style":"IPY_MODEL_171232bb06a841698fd3af2bef742cb7","value":"Best trial: 86. Best value: 0.79509: 100%"}},"ecf72f14216949e3b93f5f0f78f9baba":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf6ad7ae768647b6b317ca2266c9f784","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_02f8ea4fe50c495cb38378ca1e16dc6b","value":100}},"6e6a13c6cb6640d2b874207cb29d487e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c2094a8784c452dbf4bed4c449e1471","placeholder":"​","style":"IPY_MODEL_6a85def097714d12943770ae703d7000","value":" 100/100 [21:26&lt;00:00, 15.40s/it]"}},"7ea0dc58b97e422283f5822274fa68df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41c5428891fb4b9e8e00545c027a4794":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"171232bb06a841698fd3af2bef742cb7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf6ad7ae768647b6b317ca2266c9f784":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02f8ea4fe50c495cb38378ca1e16dc6b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7c2094a8784c452dbf4bed4c449e1471":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a85def097714d12943770ae703d7000":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["<a target=\"_blank\" href=\"https://colab.research.google.com/github/alexwolson/postdocbootcamp2023/blob/main/lab_1_2_hyperparameters.ipynb\">\n","  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n","</a>\n","\n","# UofT DSI-CARTE Postdoc Bootcamp\n","#### Monday June 19, 2023\n","#### Hyperparameter Tuning - Lab 2, Day 1\n","#### Teaching team: Alex Olson, Nakul Upadhya, Shehnaz Islam\n","##### Lab author: Nakul Upadhya (referencing work by Kyle E. C. Booth and Jake Mosseri)"],"metadata":{"id":"ACsD78d8vjSa"}},{"cell_type":"markdown","source":["Machine Learning involves solving an optimization problem to find the optimal parameters of a function that best represents the data. However, some parameters cannot be determined by this learning procedure as they define the structure of the model and the optimization process. We call these values hyperparameters, and tuning them is critical to the model development process.\n","\n","In this lab, we will cover the basics of hyperparameter tuning using Grid Search, Cross Validation, and Bayesian Optimization. Let's get started!"],"metadata":{"id":"HIPYMpobxpaD"}},{"cell_type":"code","source":["!pip install torch torchvision torchaudio\n","!pip install numpy\n","!pip install pandas\n","!pip install matplotlib\n","!pip install scikit-learn\n","!pip install optuna\n","\n","import numpy as np\n","import pandas as pd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MHB2yx2Gxpop","executionInfo":{"status":"ok","timestamp":1689198423116,"user_tz":240,"elapsed":65609,"user":{"displayName":"Nakul Upadhya","userId":"08924826005411940959"}},"outputId":"36494fc7-062f-494e-b062-2c7c91e865ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.0.2+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.40.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (8.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.22.4)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.1.0)\n","Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (3.2.0)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.11.1)\n","Requirement already satisfied: cmaes>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from optuna) (0.9.1)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.7.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.1)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.18)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.65.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.2.4)\n","Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.7.1)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n"]}]},{"cell_type":"markdown","source":["## Data Processing\n","\n","In today's lab, we're going to work with the Titanic dataset. To get it ready for our learning tasks, we need to:\n","1. Drop unimportant columns\n","2. Fix the data types of some columns\n","3. Split into Train and Test sets\n","4. Impute Missing Values\n","5. Scale the data\n","\n","We're going to do this all in the next cells:"],"metadata":{"id":"28XanXRqznHx"}},{"cell_type":"code","source":["from sklearn.datasets import fetch_openml # import function to retrieve relevant datasets\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.impute import SimpleImputer\n","from sklearn.model_selection import train_test_split\n","\n","# Read in the data\n","data = fetch_openml(\"titanic\", version=1, as_frame=True, parser='auto').frame\n","\n","# Drop unimportant columns\n","data = data.drop(['name', 'ticket', 'cabin', 'embarked', 'boat', 'body', 'home.dest'], axis=1) # remove unimportant columns\n","\n","# Fix Data types\n","le = LabelEncoder()\n","data['sex'] = pd.to_numeric(le.fit_transform(data['sex']))\n","data['survived']= pd.to_numeric(data['survived'])\n","\n","target_data = data['survived']\n","feature_data = data.drop('survived', axis = 1)\n","X_train, X_test, y_train, y_test = train_test_split(feature_data, target_data, test_size=0.25, random_state=0)\n","\n","imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n","\n","X_train = imp.fit_transform(X_train)\n","X_test = imp.transform(X_test)\n","\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","print(f\"There are {X_train.shape[0]} training data points and {X_test.shape[0]} testing points\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YUNddJ_Ez2gU","executionInfo":{"status":"ok","timestamp":1689198424388,"user_tz":240,"elapsed":1275,"user":{"displayName":"Nakul Upadhya","userId":"08924826005411940959"}},"outputId":"09e0c562-fe79-47c1-bc41-d88caac6df82"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 981 training data points and 328 testing points\n"]}]},{"cell_type":"markdown","source":["## Grid Search\n","\n","Now that we have our data set up, we can begin to talk about hyperparameter tuning. The first method we will use is grid search. This involves creating a grid of possible hyperparameter values and exhaustively evaluating the model's performance for each combination. This is commonly combined with K-Fold cross validation to get an accurate representation of the model performance. The Grid Search CV process looks like:\n","\n","1. Define the hyperparameter grid: Determine the hyperparameters you want to tune and specify the possible values for each hyperparameter. This forms a grid-like structure where each point in the grid represents a unique combination of hyperparameters.\n","\n","\n","3. Train and evaluate the model across folds: For each combination of hyperparameters, run K-Fold Cross validation with your model and evaluate the average error.\n","\n","4. Select the best hyperparameters: Choose the set of hyperparameters that yield the best performance (lowest error).\n","\n","\n","Lets see the impact of hyperparameter tuning with a simple Random Forest Classifier below.\n"],"metadata":{"id":"N5VIfGvg5CJr"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import make_scorer, accuracy_score\n","from time import time\n","\n","clf = RandomForestClassifier() # First we define our model without passing in parameters\n","hyperparameter_search = { # Then we decide the possible parameter combinations\n","    'max_depth': [3, 4, 5, 6, 7], # Max Depth of each individual tree\n","    'n_estimators': [50,100,150,200], # Number of trees generated\n","    'min_samples_leaf': [1, 2, 4, 8], # Minimum number of samples found in a leaf\n","    'min_samples_split': [2,4,8,16,32] # Minimum samples required for a split\n","}\n","\n","evaluation_metric = make_scorer(accuracy_score, # GridSearchCV requires us to wrap our metric function in a \"scorer\"\n","                                greater_is_better = True)\n","t1 = time()\n","grid_search_cv = GridSearchCV(estimator = clf,\n","                              param_grid = hyperparameter_search,\n","                              scoring = evaluation_metric,\n","                              cv = 5) # Set up search algorithm\n","\n","grid_search_cv.fit(X_train, y_train) # Run the search. NOTE: This may take a while\n","t2 = time()\n","print(f\"Time Taken: {t2-t1} seconds\")\n","\n","print(\"Best Parameters: \", grid_search_cv.best_params_) # Print the parameters\n","print (\"Best CV Accuracy: \", grid_search_cv.best_score_ * 100, \"%\")\n","\n","clf = grid_search_cv.best_estimator_ # Get the best model from the GridSearch\n","accuracy = accuracy_score(y_test, clf.predict(imp.transform(X_test)))\n","print (\"Testing Accuracy: \", accuracy * 100, \"%\") # Print the testing accuracy of the best model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3-t1k64t-O2U","executionInfo":{"status":"ok","timestamp":1689198943839,"user_tz":240,"elapsed":519453,"user":{"displayName":"Nakul Upadhya","userId":"08924826005411940959"}},"outputId":"419c2834-552c-4489-b74b-807b112d8719"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Time Taken: 519.3808827400208 seconds\n","Best Parameters:  {'max_depth': 6, 'min_samples_leaf': 1, 'min_samples_split': 8, 'n_estimators': 150}\n","Best CV Accuracy:  81.85330985185952 %\n","Testing Accuracy:  81.09756097560977 %\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but SimpleImputer was fitted with feature names\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["## Better Parameter Searching\n","While Grid Search works for many cases, one downside of this procedure is its computational complexity. For each new hyperparameter, the number of models trained increases exponentially. In the example above, there were 1024 combinations ($4^5$), meaning we needed to train a model over five thousand times ($1024 \\times 5$ folds). While this can work for a shallow model like a Random Forest or Linear/Logistic regression, the runtime can become prohibitively large for deep models such as Neural Networks or if we have a large search space\n","\n","### Introduction to Bayesian Optimization\n","Another hyperparameter approach, Bayesian Optimization, can help alleviate some of these runtime concerns. Bayesian optimization is a sequential model-based optimization technique used to find the optimal configuration of hyperparameters for a given machine learning model. It combines concepts from Bayesian inference and optimization to identify promising regions for evaluation by using a surrogate model to estimate the accuracy of our primary model with respect to its hyperparameters.\n","\n","Bayesian optimization is advantageous as it offers a more efficient exploration of the hyperparameter space than exhaustive search methods like grid search. By intelligently selecting new configurations based on the surrogate model's predictions, it converges to the optimal hyperparameters more quickly and with fewer evaluations.\n","\n","Lets try using Bayesian Optimization to search for parameters of our Random Forest. We will code this using Optuna, a hyperparameter optimization package that implements this paradigm:\n","\n"],"metadata":{"id":"iznvVdvCA7vj"}},{"cell_type":"code","source":["import optuna\n","from sklearn.model_selection import cross_validate\n","\n","# First we need to create a function that specifies our search space and trains\n","# our model. Optuna will attempt to change the value of the parameters it passes\n","# into this function to maximize the output.\n","\n","\n","def optuna_rf_function(trial):\n","\n","  # Here we define our search space. Instead of needing to pass in specific values\n","  # we can tell optuna to look for values in a specific range\n","  hyperparameter_search = {\n","    'max_depth': trial.suggest_int('max_depth', 3,7),\n","    'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n","    'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1,8),\n","    'min_samples_split': trial.suggest_int('min_samples_split', 2, 32)\n","  }\n","  ## Create the model instance\n","  model = RandomForestClassifier(**hyperparameter_search)\n","  ## Evaluate and the CV score\n","  cv_result = cross_validate(model, X_train, y_train,\n","                             cv = 5, scoring = 'accuracy')\n","  return cv_result['test_score'].mean()\n","\n","# start our Optuna study and specify the direction\n","study = optuna.create_study(direction='maximize')\n","\n","# Here we pass in our objective function and the number of combinations we want\n","# optuna to test (100 for now)\n","study.optimize(optuna_rf_function, n_trials=100,\n","               show_progress_bar=True, gc_after_trial=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["f6d84beb6f8e477a9c0d45817accc8b0","3996aef1fc0f4b7ea9a5f6dbaffd4fba","330269805d30447895208d5c4f79e728","adee0055ed694b0a9f643a489d3fb08a","76b654fd1e0a4da8b4a3bb949c286086","e05c7217178646a1b362f13e93d7fc00","6f35d1788d3b498ca7dccc8072a36daf","2d85108019624c6bb12a020175c24afe","0cd81b6de72048c8961aa7778b653a0b","9a08383cb3b24b129429c401fa4e8df4","1b58e8e784a045e08d6605205d63150a"]},"id":"nEDytL6uA4oU","executionInfo":{"status":"ok","timestamp":1689199069057,"user_tz":240,"elapsed":125228,"user":{"displayName":"Nakul Upadhya","userId":"08924826005411940959"}},"outputId":"8625709b-04be-468e-f957-c84f3972c85d"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6d84beb6f8e477a9c0d45817accc8b0"}},"metadata":{}}]},{"cell_type":"code","source":["best_params = study.best_params\n","best_accuracy = study.best_value\n","\n","print(\"Best Parameters: \", best_params)\n","print(\"Best CV Accuracy: \", best_accuracy * 100, \"%\")\n","\n","best_model = RandomForestClassifier(**best_params)\n","best_model.fit(X_train, y_train)\n","\n","y_pred = best_model.predict(X_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Testing Accuracy: \", accuracy * 100, \"%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c6RsdF9nJCkF","executionInfo":{"status":"ok","timestamp":1689199069230,"user_tz":240,"elapsed":183,"user":{"displayName":"Nakul Upadhya","userId":"08924826005411940959"}},"outputId":"85f309ba-77a8-4720-991c-7d1dbf2ddf84"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Parameters:  {'max_depth': 7, 'n_estimators': 78, 'min_samples_leaf': 1, 'min_samples_split': 17}\n","Best CV Accuracy:  81.7528229565938 %\n","Testing Accuracy:  80.79268292682927 %\n"]}]},{"cell_type":"markdown","source":["**Your Turn**\n","* How does the CV accuracy of the grid search and Optuna compare? ______________\n","* How does the testing accuracy compare? ______________\n","* Which one ran faster and why do you think that is? ______________\n","\n","### Tuning a Neural Network\n","One reason to use Bayesian Optimization is to help with the parameter tuning of neural networks. These models often take much longer to train and can be sensitive to hyperparameters such as the dropout, learning rate, weight decay, batch size, and other parameters. Lets see how we can tune these parameyers for a neural network.\n","\n","#### Creating our network\n","\n","Lets create a simple neural network seperated by a ReLu non-linearities. We will also wrap our training and prediction logic within this class to simplify the hyperparameter search process.\n","\n","In this network, our hyperparameters will be:\n","1. The batch size used for training\n","2. The learning rate for training\n","3. The number of training epochs\n","3. The size of the hidden dimension of the network.\n","\n"],"metadata":{"id":"KfQzBH9VKUyU"}},{"cell_type":"code","source":["import torch\n","from torch import nn\n","from torch.optim import Adam\n","from torch.autograd import Variable\n","from torch.utils.data import TensorDataset, DataLoader\n","class TitanicMLP(nn.Module):\n","  \"\"\" Simple two layer network \"\"\"\n","  def __init__(self,\n","               input_dim,\n","               hidden_dim,\n","               batch_size,\n","               learning_rate,\n","               epochs):\n","      super(TitanicMLP, self).__init__()\n","\n","      self.input_dim = input_dim\n","      self.hidden_dim = hidden_dim\n","      self.batch_size = batch_size\n","      self.learning_rate = learning_rate\n","      self.epochs = epochs\n","\n","      self.forward_pass = nn.Sequential(\n","          nn.Linear(input_dim, hidden_dim),\n","          nn.ReLU(),\n","          nn.Linear(hidden_dim, 1)\n","      )\n","\n","\n","  def forward(self, x):\n","      return self.forward_pass(x)\n","\n","  def fit(self, X, y):\n","    self.train()\n","    # Create tensors from our inputs\n","    X_tensor = Variable(torch.Tensor(X_train)).float()\n","    Y_tensor = Variable(torch.Tensor(y_train.values)).float()\n","    train_dataset = TensorDataset(X_tensor, Y_tensor)\n","\n","    # set up the DataLoader\n","    train_loader = DataLoader(dataset=train_dataset,\n","                              batch_size=self.batch_size,\n","                              shuffle=True)\n","    # Define our loss function and optimizer\n","    criterion = nn.BCEWithLogitsLoss()\n","    optimizer = torch.optim.SGD(self.parameters(), lr=self.learning_rate)\n","\n","    for epoch in range(self.epochs):\n","      for batch_idx, (features, target) in enumerate(train_loader):\n","\n","        optimizer.zero_grad()\n","        outputs = self.forward(features)\n","        loss = criterion(torch.squeeze(outputs), torch.squeeze(target))\n","        loss.backward()\n","        optimizer.step()\n","\n","  def predict(self, X):\n","    self.eval()\n","    with torch.no_grad():\n","      X_tensor = torch.Tensor(X)\n","      y_pred = torch.sigmoid(self.forward(X_tensor))\n","      y_pred = torch.round(y_pred).squeeze().numpy()\n","      return y_pred\n"],"metadata":{"id":"ckZ8n0ZOKTbF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now lets set up Optuna. Due our network class having a `fit` and `predict` function, we can actually re-use a lot of our code from the Random Forest.\n","\n","**Your Turn**\n","* Current the Hyperparameter search has some dummy values passed in. Configure the search for `hidden_dim`, `batch_size`, `learning_rate`, and `epochs` based on values you think are reasonable and run the hyperparameter search.\n","* Look at the scores generated for the various parameter configurations tested by Optuna. Are they similar to each other, or do they drastically impact the model performance?"],"metadata":{"id":"pLPKZ119ZUHn"}},{"cell_type":"code","source":["from sklearn.model_selection import StratifiedKFold\n","\n","def optuna_mlp_function(trial):\n","\n","  HP = {\n","    'input_dim': trial.suggest_categorical('input_dim', [X_train.shape[1]]), # Don't change this\n","    'hidden_dim': trial.suggest_int('hidden_dim', 1, 1e6), # Change this\n","    'batch_size': trial.suggest_int('batch_size', 1, 1e6), # Change this\n","    'learning_rate': trial.suggest_float('learning_rate', 1, 1e6), # Change this\n","    'epochs': trial.suggest_int('epochs', 1,1e6) # Change this\n","  }\n","  ## Create the model instance\n","  model = TitanicMLP(**HP)\n","  scores = []\n","  kfold = StratifiedKFold(n_splits = 5)\n","  for i, (train_index, test_index) in enumerate(kfold.split(X_train, y_train)):\n","    X_fold = X_train[train_index]\n","    y_fold = y_train.values[train_index]\n","    X_test_fold = X_train[test_index]\n","    y_test_fold = y_train.values[test_index]\n","    model.fit(X_fold, y_fold)\n","    y_pred = model.predict(X_test_fold)\n","    scores.append(accuracy_score(y_test_fold, y_pred))\n","  return np.mean(scores)\n","# start our Optuna study and specify the direction\n","mlp_study = optuna.create_study(direction='maximize')\n","\n","# Here we pass in our objective function and the number of combinations we want\n","# optuna to test (100 for now)\n","mlp_study.optimize(optuna_mlp_function, n_trials=100,\n","                    show_progress_bar=True, gc_after_trial=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["e0aef6ccaf6d43e1b5c400b2307a265e","f21470133c574f5c9d0707c979038cbf","ecf72f14216949e3b93f5f0f78f9baba","6e6a13c6cb6640d2b874207cb29d487e","7ea0dc58b97e422283f5822274fa68df","41c5428891fb4b9e8e00545c027a4794","171232bb06a841698fd3af2bef742cb7","cf6ad7ae768647b6b317ca2266c9f784","02f8ea4fe50c495cb38378ca1e16dc6b","7c2094a8784c452dbf4bed4c449e1471","6a85def097714d12943770ae703d7000"]},"id":"JNAl8udWXi8v","executionInfo":{"status":"ok","timestamp":1689200358759,"user_tz":240,"elapsed":1286587,"user":{"displayName":"Nakul Upadhya","userId":"08924826005411940959"}},"outputId":"d139da5c-1812-460a-a91a-9d38284391d5"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0aef6ccaf6d43e1b5c400b2307a265e"}},"metadata":{}}]},{"cell_type":"code","source":["best_params = mlp_study.best_params\n","best_accuracy = mlp_study.best_value\n","print(\"Best Parameters: \", mlp_study.best_params)\n","print(\"Best CV Accuracy: \", mlp_study.best_value * 100, \"%\")\n","\n","\n","best_model = TitanicMLP(**best_params)\n","best_model.fit(X_train, y_train)\n","\n","y_pred = best_model.predict(X_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Testing Accuracy: \", accuracy * 100, \"%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XU5CsRnAa4N9","executionInfo":{"status":"ok","timestamp":1689200362022,"user_tz":240,"elapsed":3265,"user":{"displayName":"Nakul Upadhya","userId":"08924826005411940959"}},"outputId":"34f5c470-8cb0-4152-93c1-a5b6277475a8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Parameters:  {'input_dim': 6, 'hidden_dim': 58, 'batch_size': 131, 'learning_rate': 0.0009881690355287936, 'epochs': 232}\n","Best CV Accuracy:  79.50896094478401 %\n","Testing Accuracy:  75.3048780487805 %\n"]}]},{"cell_type":"markdown","source":["**Your Turn**\n","* Apart from the values we searched for above, what other parameters do you think can be tuned in a Neural Network?\n"],"metadata":{"id":"in1P8TDhF8jV"}}]}